{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zengs/data/anaconda3/envs/venv_pl/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "sys.path.append('..')\n",
    "sys.path.append('.')\n",
    "sys.path.append('../llm_garden')\n",
    "\n",
    "from peft_modules import peft_utils\n",
    "import esm_adapter\n",
    "\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# torch.hub.set_dir(\"./torch_hub\")\n",
    "torch.hub.set_dir(\"/home/zengs/zengs_data/torch_hub\")\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dtype = torch.double\n",
    "\n",
    "\n",
    "\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")\n",
    "N_TRIALS = 3 if not SMOKE_TEST else 2\n",
    "N_BATCH = 20 if not SMOKE_TEST else 2\n",
    "MC_SAMPLES = 256 if not SMOKE_TEST else 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  5, 15, 11,  7, 10, 16,  9, 10,  4, 15,  2],\n",
       "         [ 0, 25,  5,  4, 11,  5, 10, 16, 16,  9,  7,  2],\n",
       "         [ 0, 13, 15,  9,  7, 18, 13,  4, 12, 10, 13,  2],\n",
       "         [ 0,  9, 10, 13, 21, 12,  8, 16, 11,  6, 20,  2]]),\n",
       " torch.Size([4, 12]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_SEQ_SIZE = 10\n",
    "\n",
    "\n",
    "# data\n",
    "data = peft_utils.get_esm_example_data(INPUT_SEQ_SIZE)\n",
    "\n",
    "\n",
    "# Load ESM-2 model\n",
    "# esm2_t33_650M_UR50D\n",
    "# esm2_t6_8M_UR50D\n",
    "model, alphabet = esm_adapter.pretrained.esm2_t6_8M_UR50D()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "model.eval()\n",
    "\n",
    "batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "\n",
    "batch_tokens, batch_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.9543e-01, -2.7515e-01, -1.4941e-01,  ...,  1.2744e-01,\n",
       "           -1.0431e-01, -6.4697e-02],\n",
       "          [-6.6711e-02, -1.1932e-02,  8.6288e-03,  ...,  1.4633e-02,\n",
       "           -4.3945e-02, -1.9348e-01],\n",
       "          [-9.7595e-02,  1.5762e-02,  3.3600e-02,  ...,  3.4027e-03,\n",
       "            2.2369e-02,  2.8732e-02],\n",
       "          ...,\n",
       "          [-8.5693e-02, -2.2476e-02,  4.2603e-02,  ...,  8.2764e-02,\n",
       "            8.9539e-02,  8.9417e-02],\n",
       "          [-9.7595e-02,  1.5762e-02,  3.3600e-02,  ...,  3.4027e-03,\n",
       "            2.2369e-02,  2.8732e-02],\n",
       "          [ 7.3120e-02, -3.0811e-01, -1.1700e-01,  ..., -2.2058e-01,\n",
       "           -3.4326e-01, -1.5488e-03]],\n",
       " \n",
       "         [[-1.9543e-01, -2.7515e-01, -1.4941e-01,  ...,  1.2744e-01,\n",
       "           -1.0431e-01, -6.4697e-02],\n",
       "          [ 2.0813e-02, -8.6548e-02, -7.0374e-02,  ..., -2.9898e-04,\n",
       "           -8.3923e-02, -1.3000e-01],\n",
       "          [-6.6711e-02, -1.1932e-02,  8.6288e-03,  ...,  1.4633e-02,\n",
       "           -4.3945e-02, -1.9348e-01],\n",
       "          ...,\n",
       "          [-8.1055e-02, -3.8483e-02,  1.6222e-03,  ...,  4.4708e-02,\n",
       "            6.1722e-03, -8.3327e-05],\n",
       "          [-7.1716e-02, -1.5152e-02,  9.3079e-03,  ...,  7.3792e-02,\n",
       "            5.2002e-02,  1.0368e-02],\n",
       "          [ 7.3120e-02, -3.0811e-01, -1.1700e-01,  ..., -2.2058e-01,\n",
       "           -3.4326e-01, -1.5488e-03]],\n",
       " \n",
       "         [[-1.9543e-01, -2.7515e-01, -1.4941e-01,  ...,  1.2744e-01,\n",
       "           -1.0431e-01, -6.4697e-02],\n",
       "          [-9.0515e-02, -2.1042e-02,  7.9422e-03,  ...,  6.4575e-02,\n",
       "            2.1851e-01, -3.4302e-02],\n",
       "          [-9.7595e-02,  1.5762e-02,  3.3600e-02,  ...,  3.4027e-03,\n",
       "            2.2369e-02,  2.8732e-02],\n",
       "          ...,\n",
       "          [-9.8877e-02, -3.5400e-02, -4.0344e-02,  ...,  2.3346e-02,\n",
       "            2.4582e-02,  1.1053e-01],\n",
       "          [-9.0515e-02, -2.1042e-02,  7.9422e-03,  ...,  6.4575e-02,\n",
       "            2.1851e-01, -3.4302e-02],\n",
       "          [ 7.3120e-02, -3.0811e-01, -1.1700e-01,  ..., -2.2058e-01,\n",
       "           -3.4326e-01, -1.5488e-03]],\n",
       " \n",
       "         [[-1.9543e-01, -2.7515e-01, -1.4941e-01,  ...,  1.2744e-01,\n",
       "           -1.0431e-01, -6.4697e-02],\n",
       "          [-8.1055e-02, -3.8483e-02,  1.6222e-03,  ...,  4.4708e-02,\n",
       "            6.1722e-03, -8.3327e-05],\n",
       "          [-9.8877e-02, -3.5400e-02, -4.0344e-02,  ...,  2.3346e-02,\n",
       "            2.4582e-02,  1.1053e-01],\n",
       "          ...,\n",
       "          [-1.0071e-01, -7.9498e-03, -3.6035e-01,  ..., -6.2073e-02,\n",
       "            6.1615e-02,  4.3335e-02],\n",
       "          [-1.2018e-01, -6.2561e-02, -3.1189e-02,  ..., -2.5317e-01,\n",
       "            4.7913e-02, -8.8928e-02],\n",
       "          [ 7.3120e-02, -3.0811e-01, -1.1700e-01,  ..., -2.2058e-01,\n",
       "           -3.4326e-01, -1.5488e-03]]], grad_fn=<EmbeddingBackward0>),\n",
       " torch.Size([4, 12, 320]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embedding = model.embed_tokens(batch_tokens)\n",
    "\n",
    "\n",
    "# torch.Size([4, 12, 320])) # (N_SEQ, N_TOKEN, N_FEAT)\n",
    "token_embedding, token_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.test_functions import Hartmann\n",
    "from botorch.models import FixedNoiseGP, ModelListGP\n",
    "from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n",
    "\n",
    "\n",
    "neg_hartmann6 = Hartmann(negate=True)\n",
    "NOISE_SE = 0.5\n",
    "train_yvar = torch.tensor(NOISE_SE**2, device=device, dtype=dtype)\n",
    "\n",
    "\n",
    "def outcome_constraint(X):\n",
    "    \"\"\"L1 constraint; feasible if less than or equal to zero.\"\"\"\n",
    "    return X.sum(dim=-1) - 3\n",
    "\n",
    "\n",
    "def weighted_obj(X):\n",
    "    \"\"\"Feasibility weighted objective; zero if not feasible.\"\"\"\n",
    "    return neg_hartmann6(X) * (outcome_constraint(X) <= 0).type_as(X)\n",
    "\n",
    "\n",
    "def generate_initial_data(n=10):\n",
    "    # generate training data\n",
    "    # train_x = torch.rand(10, 6, device=device, dtype=dtype)\n",
    "    # exact_obj = neg_hartmann6(train_x).unsqueeze(-1)  # add output dimension\n",
    "    # exact_con = outcome_constraint(train_x).unsqueeze(-1)  # add output dimension\n",
    "    # train_obj = exact_obj + NOISE_SE * torch.randn_like(exact_obj)\n",
    "    # train_con = exact_con + NOISE_SE * torch.randn_like(exact_con)\n",
    "\n",
    "\n",
    "    train_x = torch.randint(4, 29, size=(10, 6), device=device)\n",
    "    train_x = train_x.to(device=device, dtype=dtype)\n",
    "\n",
    "    # TODO: change these to the actual objective and constraint values\n",
    "    exact_obj = torch.rand(10, 1, device=device, dtype=dtype)\n",
    "    exact_con = outcome_constraint(train_x).unsqueeze(-1)  # add output dimension\n",
    "    train_obj = exact_obj\n",
    "    train_con = exact_con\n",
    "\n",
    "    train_obj = train_obj.to(device=device, dtype=dtype)\n",
    "    train_con = train_con.to(device=device, dtype=dtype)\n",
    "\n",
    "    # best_observed_value = torch.rand(10, 1, device=device, dtype=dtype)\n",
    "    best_observed_value = weighted_obj(train_x).max().item()\n",
    "    return train_x, train_obj, train_con, best_observed_value\n",
    "\n",
    "\n",
    "def initialize_model(train_x, train_obj, train_con, state_dict=None):\n",
    "    # define models for objective and constraint\n",
    "    train_x = train_x.to(device=device, dtype=dtype)\n",
    "    train_obj = train_obj.to(device=device, dtype=dtype)\n",
    "    train_con = train_con.to(device=device, dtype=dtype)\n",
    "\n",
    "    # print(train_x)\n",
    "\n",
    "    model_obj = FixedNoiseGP(train_x, train_obj, train_yvar.expand_as(train_obj)).to(\n",
    "        train_x\n",
    "    )\n",
    "    model_con = FixedNoiseGP(train_x, train_con, train_yvar.expand_as(train_con)).to(\n",
    "        train_x\n",
    "    )\n",
    "    # combine into a multi-output GP model\n",
    "    model = ModelListGP(model_obj, model_con)\n",
    "    mll = SumMarginalLogLikelihood(model.likelihood, model)\n",
    "    # load state dict if it is passed\n",
    "    if state_dict is not None:\n",
    "        model.load_state_dict(state_dict)\n",
    "    return mll, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.acquisition.objective import ConstrainedMCObjective\n",
    "\n",
    "\n",
    "def obj_callable(Z):\n",
    "    return Z[..., 0]\n",
    "\n",
    "\n",
    "def constraint_callable(Z):\n",
    "    return Z[..., 1]\n",
    "\n",
    "\n",
    "# define a feasibility-weighted objective for optimization\n",
    "constrained_obj = ConstrainedMCObjective(\n",
    "    objective=obj_callable,\n",
    "    constraints=[constraint_callable],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "\n",
    "bounds = torch.tensor([[0.0] * 6, [1.0] * 6], device=device, dtype=dtype)\n",
    "\n",
    "BATCH_SIZE = 3 if not SMOKE_TEST else 2\n",
    "NUM_RESTARTS = 10 if not SMOKE_TEST else 2\n",
    "RAW_SAMPLES = 512 if not SMOKE_TEST else 32\n",
    "\n",
    "\n",
    "def optimize_acqf_and_get_observation(acq_func):\n",
    "    \"\"\"Optimizes the acquisition function, and returns a new candidate and a noisy observation.\"\"\"\n",
    "    # optimize\n",
    "    candidates, _ = optimize_acqf(\n",
    "        acq_function=acq_func,\n",
    "        bounds=bounds,\n",
    "        q=BATCH_SIZE,\n",
    "        num_restarts=NUM_RESTARTS,\n",
    "        raw_samples=RAW_SAMPLES,  # used for intialization heuristic\n",
    "        options={\"batch_limit\": 5, \"maxiter\": 200},\n",
    "    )\n",
    "    # observe new values\n",
    "    new_x = candidates.detach()\n",
    "    exact_obj = neg_hartmann6(new_x).unsqueeze(-1)  # add output dimension\n",
    "    exact_con = outcome_constraint(new_x).unsqueeze(-1)  # add output dimension\n",
    "    new_obj = exact_obj + NOISE_SE * torch.randn_like(exact_obj)\n",
    "    new_con = exact_con + NOISE_SE * torch.randn_like(exact_con)\n",
    "    return new_x, new_obj, new_con\n",
    "\n",
    "\n",
    "def update_random_observations(best_random):\n",
    "    \"\"\"Simulates a random policy by taking a the current list of best values observed randomly,\n",
    "    drawing a new random point, observing its value, and updating the list.\n",
    "    \"\"\"\n",
    "    rand_x = torch.rand(BATCH_SIZE, 6)\n",
    "    next_random_best = weighted_obj(rand_x).max().item()\n",
    "    best_random.append(max(best_random[-1], next_random_best))\n",
    "    return best_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch import fit_gpytorch_mll\n",
    "from botorch.acquisition.monte_carlo import (\n",
    "    qExpectedImprovement,\n",
    "    qNoisyExpectedImprovement,\n",
    ")\n",
    "from botorch.sampling.normal import SobolQMCNormalSampler\n",
    "from botorch.exceptions import BadInitialCandidatesWarning\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=BadInitialCandidatesWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "\n",
    "N_TRIALS = 3 if not SMOKE_TEST else 2\n",
    "N_BATCH = 20 if not SMOKE_TEST else 2\n",
    "MC_SAMPLES = 256 if not SMOKE_TEST else 32\n",
    "\n",
    "verbose = False\n",
    "\n",
    "best_observed_all_ei, best_observed_all_nei, best_random_all = [], [], []\n",
    "\n",
    "\n",
    "N_TRIALS = 1\n",
    "N_BATCH = 1\n",
    "# average over multiple trials\n",
    "for trial in range(1, N_TRIALS + 1):\n",
    "\n",
    "    print(f\"\\nTrial {trial:>2} of {N_TRIALS} \", end=\"\")\n",
    "    best_observed_ei, best_observed_nei, best_random = [], [], []\n",
    "\n",
    "    # call helper functions to generate initial training data and initialize model\n",
    "    (\n",
    "        train_x_ei,\n",
    "        train_obj_ei,\n",
    "        train_con_ei,\n",
    "        best_observed_value_ei,\n",
    "    ) = generate_initial_data(n=10)\n",
    "\n",
    "    train_x_nei, train_obj_nei, train_con_nei = train_x_ei, train_obj_ei, train_con_ei\n",
    "    mll_nei, model_nei = initialize_model(train_x_nei, train_obj_nei, train_con_nei)\n",
    "\n",
    "    best_observed_value_nei = best_observed_value_ei\n",
    "    best_observed_ei.append(best_observed_value_ei)\n",
    "    best_observed_nei.append(best_observed_value_nei)\n",
    "    best_random.append(best_observed_value_ei)\n",
    "\n",
    "    # run N_BATCH rounds of BayesOpt after the initial random batch\n",
    "    for iteration in range(1, N_BATCH + 1):\n",
    "\n",
    "        t0 = time.monotonic()\n",
    "\n",
    "        # fit the models\n",
    "        fit_gpytorch_mll(mll_nei)\n",
    "        \n",
    "        # define the qEI and qNEI acquisition modules using a QMC sampler\n",
    "        qmc_sampler = SobolQMCNormalSampler(sample_shape=torch.Size([MC_SAMPLES]))\n",
    "    \n",
    "        qNEI = qNoisyExpectedImprovement(\n",
    "            model=model_nei,\n",
    "            X_baseline=train_x_nei,\n",
    "            sampler=qmc_sampler,\n",
    "            objective=constrained_obj,\n",
    "        )\n",
    "\n",
    "        new_x_nei, new_obj_nei, new_con_nei = optimize_acqf_and_get_observation(qNEI)\n",
    "        \n",
    "        print(train_x_nei)\n",
    "        train_x_nei = torch.cat([train_x_nei, new_x_nei])\n",
    "        print(train_x_nei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x_nei\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_pl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
